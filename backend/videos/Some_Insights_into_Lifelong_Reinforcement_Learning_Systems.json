{
  "id": "7fd108d8-6a59-4c4f-bb56-634a299830be",
  "title": "Some Insights into Lifelong Reinforcement Learning Systems",
  "videoUrl": "https://paper-bites.s3.amazonaws.com/videos/054dddd3-4a35-4265-b9ce-d932ddd9ee60_Some_Insights_into_Lifelong_Reinforcement_Learning_Systems.mp4",
  "summary": "An agent is an abstraction of a decision-maker. At each time t, it receives an observation ot O, and outputs an action at A. An agent\u2019s observation ot depends on the cur- \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0rent environment state st. (a) unbiased policy, progressed-based guidance\n(b) biased policy, progressed-based guidance\nFigure 5: Learning curve for unbiased/biased policy with\nprogress-based guidance, averaged over 20 runs. Lifelong reinforcement learning is sometimes viewed as a multi-task reinforcement learning problem.",
  "keywords": [
    "possible observations",
    "agent",
    "learning",
    "observation",
    "policy",
    "environment",
    "guidance",
    "lifelong"
  ],
  "hashtags": "#possibleobservations #agent #learning #observation #policy #environment #guidance #lifelong",
  "key_insights": [
    "The observation history ho t = (o1, o2..., ot) is the sequence of observations the agent has received till time...",
    "Lifelong reinforcement learning is sometimes viewed as a multi-task reinforcement learning problem (Abel et al., 2018), where the agent must...",
    "At each time instance t, it receives an observation ot \u2208O, and outputs an action at \u2208A to be carried..."
  ],
  "paper_id": "2001.09608v1",
  "url": "http://arxiv.org/pdf/2001.09608v1",
  "license": "arXiv",
  "authors": [
    "Changjian Li"
  ],
  "timestamp": 1746649380,
  "can_display_publicly": true
}